{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7af3c4a",
   "metadata": {},
   "source": [
    "# DermoSegDiff Training Notebook\n",
    "\n",
    "This notebook provides a complete pipeline for training DermoSegDiff on custom skin lesion segmentation data.\n",
    "\n",
    "## Data Structure Expected:\n",
    "```\n",
    "data_dir/\n",
    "├── train/\n",
    "│   ├── images/ (*.jpg)\n",
    "│   └── masks/ (*.png - binary 0,255)\n",
    "├── val/\n",
    "│   ├── images/ (*.jpg)\n",
    "│   └── masks/ (*.png - binary 0,255)\n",
    "└── test/\n",
    "    └── images/ (*.jpg - no masks)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('src')\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bf1c9",
   "metadata": {},
   "source": [
    "## Configuration Setup\n",
    "\n",
    "Define the training configuration for your custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d20d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for custom dataset\n",
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"name\": \"custom\",\n",
    "        \"class_name\": \"CustomDatasetFast\", \n",
    "        \"data_dir\": \"/path/to/your/data\",  # CHANGE THIS TO YOUR DATA PATH\n",
    "        \"input_size\": 256,\n",
    "        \"img_channels\": 3,\n",
    "        \"msk_channels\": 1,\n",
    "        \"add_boundary_mask\": False,\n",
    "        \"add_boundary_dist\": False\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": \"dermosegdiff_custom\",\n",
    "        \"class\": \"DermoSegDiff\",\n",
    "        \"save_dir\": \"weights\",\n",
    "        \"params\": {\n",
    "            \"dim_x\": 128,\n",
    "            \"dim_g\": 64,\n",
    "            \"channels_x\": 1,\n",
    "            \"channels_g\": 3,\n",
    "            \"dim_mults\": [1, 2, 4, 8],\n",
    "            \"resnet_block_groups\": 4\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"epochs\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"name\": \"AdamW\",\n",
    "            \"params\": {\n",
    "                \"lr\": 1e-4,\n",
    "                \"betas\": [0.9, 0.999],\n",
    "                \"weight_decay\": 1e-4\n",
    "            }\n",
    "        },\n",
    "        \"scheduler\": {\n",
    "            \"factor\": 0.5,\n",
    "            \"patience\": 10,\n",
    "            \"min_lr\": 1e-7\n",
    "        },\n",
    "        \"loss\": {\n",
    "            \"mse\": {\"weight\": 1.0}\n",
    "        },\n",
    "        \"ema\": {\n",
    "            \"use\": True,\n",
    "            \"params\": {\n",
    "                \"beta\": 0.9999,\n",
    "                \"update_every\": 10\n",
    "            }\n",
    "        },\n",
    "        \"intial_weights\": {\n",
    "            \"use\": False,\n",
    "            \"file_path\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"diffusion\": {\n",
    "        \"schedule\": {\n",
    "            \"timesteps\": 1000,\n",
    "            \"mode\": \"cosine\",\n",
    "            \"beta_start\": 0.0001,\n",
    "            \"beta_end\": 0.02\n",
    "        }\n",
    "    },\n",
    "    \"data_loader\": {\n",
    "        \"train\": {\n",
    "            \"batch_size\": 4,\n",
    "            \"shuffle\": True,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": True\n",
    "        },\n",
    "        \"validation\": {\n",
    "            \"batch_size\": 4,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"batch_size\": 1,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False\n",
    "        }\n",
    "    },\n",
    "    \"run\": {\n",
    "        \"device\": device,\n",
    "        \"continue_training\": False,\n",
    "        \"writer_dir\": \"runs\"\n",
    "    },\n",
    "    \"testing\": {\n",
    "        \"ensemble\": 1,\n",
    "        \"model_weigths\": {\n",
    "            \"overload\": False,\n",
    "            \"file_path\": \"\"\n",
    "        },\n",
    "        \"result_imgs\": {\n",
    "            \"save\": True,\n",
    "            \"dir\": \"results\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# IMPORTANT: Change this to your actual data directory\n",
    "config[\"dataset\"][\"data_dir\"] = input(\"Enter your data directory path: \")\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ceda63",
   "metadata": {},
   "source": [
    "## Data Verification\n",
    "\n",
    "Let's verify your data structure and visualize some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data structure\n",
    "data_dir = config[\"dataset\"][\"data_dir\"]\n",
    "\n",
    "train_images = glob.glob(os.path.join(data_dir, \"train\", \"images\", \"*.jpg\"))\n",
    "train_masks = glob.glob(os.path.join(data_dir, \"train\", \"masks\", \"*.png\"))\n",
    "val_images = glob.glob(os.path.join(data_dir, \"val\", \"images\", \"*.jpg\"))\n",
    "val_masks = glob.glob(os.path.join(data_dir, \"val\", \"masks\", \"*.png\"))\n",
    "test_images = glob.glob(os.path.join(data_dir, \"test\", \"images\", \"*.jpg\"))\n",
    "\n",
    "print(\"Data Statistics:\")\n",
    "print(f\"Training Images: {len(train_images)}\")\n",
    "print(f\"Training Masks: {len(train_masks)}\")\n",
    "print(f\"Validation Images: {len(val_images)}\")\n",
    "print(f\"Validation Masks: {len(val_masks)}\")\n",
    "print(f\"Test Images: {len(test_images)}\")\n",
    "\n",
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i in range(3):\n",
    "    if i < len(train_images):\n",
    "        # Load image\n",
    "        img_path = train_images[i]\n",
    "        mask_path = train_masks[i]\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        \n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title(f\"Train Image {i+1}\")\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        axes[1, i].imshow(mask, cmap='gray')\n",
    "        axes[1, i].set_title(f\"Train Mask {i+1}\")\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6a194",
   "metadata": {},
   "source": [
    "## Import Required Modules\n",
    "\n",
    "Import all necessary modules for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be79946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper_funcs import (\n",
    "    get_model_path,\n",
    "    get_conf_name,\n",
    "    print_config,\n",
    ")\n",
    "from models import *\n",
    "from forward.forward_schedules import ForwardSchedule\n",
    "from forward.forward_process import ForwardProcess\n",
    "from torch.optim import lr_scheduler, AdamW\n",
    "from train_validate import train, validate\n",
    "from loaders.dataloaders import get_dataloaders\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from common.logging import get_logger\n",
    "from ema_pytorch import EMA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b95f1e",
   "metadata": {},
   "source": [
    "## Setup Training Components\n",
    "\n",
    "Initialize model, optimizer, scheduler, and other training components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98672d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "Path(config[\"model\"][\"save_dir\"]).mkdir(exist_ok=True, parents=True)\n",
    "Path(config[\"run\"][\"writer_dir\"]).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Setup logging\n",
    "logger = get_logger(filename=f\"{config['model']['name']}\", dir=\"logs\")\n",
    "print_config(config, logger)\n",
    "\n",
    "# Create tensorboard writer\n",
    "writer = SummaryWriter(f'{config[\"run\"][\"writer_dir\"]}/{config[\"model\"][\"name\"]}')\n",
    "\n",
    "# Get configuration name\n",
    "ID = get_conf_name(config)\n",
    "print(f\"Configuration ID: {ID}\")\n",
    "\n",
    "# Setup forward process\n",
    "forward_schedule = ForwardSchedule(**config[\"diffusion\"][\"schedule\"])\n",
    "forward_process = ForwardProcess(forward_schedule)\n",
    "\n",
    "# Get dataloaders\n",
    "tr_dataloader, vl_dataloader = get_dataloaders(config, [\"tr\", \"vl\"])\n",
    "\n",
    "print(f\"Training batches: {len(tr_dataloader)}\")\n",
    "print(f\"Validation batches: {len(vl_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "Net = globals()[config[\"model\"][\"class\"]]\n",
    "model = Net(**config[\"model\"][\"params\"])\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "logger.info(f\"Number of model parameters: {total_params:,}\")\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = AdamW(model.parameters(), **config[\"training\"][\"optimizer\"][\"params\"])\n",
    "\n",
    "# Setup scheduler\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", **config[\"training\"][\"scheduler\"])\n",
    "\n",
    "# Setup EMA\n",
    "if config[\"training\"][\"ema\"][\"use\"]:\n",
    "    ema = EMA(model=model, **config[\"training\"][\"ema\"][\"params\"])\n",
    "    ema.to(device)\n",
    "else:\n",
    "    ema = None\n",
    "\n",
    "print(\"Model and training components initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc64b6",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variables\n",
    "epochs = config[\"training\"][\"epochs\"]\n",
    "start_epoch = 0\n",
    "best_vl_loss = np.Inf\n",
    "\n",
    "print(f\"Starting training for {epochs} epochs...\")\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    print(f\"\\n=== Epoch {epoch+1}/{epochs} ===\")\n",
    "    \n",
    "    # Training\n",
    "    tr_losses, model = train(\n",
    "        model,\n",
    "        tr_dataloader,\n",
    "        forward_process,\n",
    "        device,\n",
    "        optimizer,\n",
    "        ema=ema,\n",
    "        cfg=config,\n",
    "        extra={\"skip_steps\": 10, \"prefix\": f\"ep:{epoch+1}/{epochs}\"},\n",
    "        logger=logger\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    vl_losses = validate(\n",
    "        ema.ema_model if ema else model,\n",
    "        vl_dataloader,\n",
    "        forward_process,\n",
    "        device,\n",
    "        cfg=config,\n",
    "        vl_runs=3,\n",
    "        logger=logger\n",
    "    )\n",
    "    \n",
    "    # Calculate average losses\n",
    "    tr_loss = np.mean([l[0] for l in tr_losses])\n",
    "    vl_loss = np.mean([l[0] for l in vl_losses])\n",
    "    \n",
    "    # Log to tensorboard\n",
    "    writer.add_scalars(\n",
    "        f\"Loss/train vs validation/{config['training']['loss_name']}\",\n",
    "        {\"Train\": tr_loss, \"Validation\": vl_loss},\n",
    "        epoch,\n",
    "    )\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(vl_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {tr_loss:.6f}, Val Loss = {vl_loss:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if best_vl_loss > vl_loss:\n",
    "        print(f\">>> New best model! Previous: {best_vl_loss:.6f}, Current: {vl_loss:.6f}\")\n",
    "        best_vl_loss = vl_loss\n",
    "        \n",
    "        model_path = get_model_path(name=ID, dir=config[\"model\"][\"save_dir\"])\n",
    "        checkpoint = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"epochs\": epochs,\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"ema\": ema.state_dict() if ema else None,\n",
    "            \"vl_loss\": vl_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, model_path)\n",
    "        print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "writer.flush()\n",
    "writer.close()\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03f515",
   "metadata": {},
   "source": [
    "## Testing and Prediction\n",
    "\n",
    "Load the best model and make predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0733e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverse.reverse_process import sample\n",
    "from modules.transforms import DiffusionTransform\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Load best model\n",
    "model_path = get_model_path(name=ID, dir=config[\"model\"][\"save_dir\"])\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "if ema:\n",
    "    ema.load_state_dict(checkpoint[\"ema\"])\n",
    "    model = ema.ema_model\n",
    "else:\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Best model loaded from: {model_path}\")\n",
    "print(f\"Best validation loss: {checkpoint['vl_loss']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dataloader\n",
    "te_dataloader = get_dataloaders(config, \"te\")\n",
    "DT = DiffusionTransform((config[\"dataset\"][\"input_size\"], config[\"dataset\"][\"input_size\"]))\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"predicted_masks\"\n",
    "Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"Starting prediction on {len(te_dataloader)} test images...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(te_dataloader):\n",
    "        batch_imgs = batch[\"image\"].to(device)\n",
    "        batch_ids = batch[\"id\"]\n",
    "        \n",
    "        # Generate predictions\n",
    "        samples = sample(\n",
    "            forward_schedule,\n",
    "            model,\n",
    "            images=batch_imgs,\n",
    "            out_channels=1,\n",
    "            desc=f\"Predicting {step+1}/{len(te_dataloader)}\",\n",
    "        )\n",
    "        \n",
    "        preds = samples[-1][:, :1, :, :].to(device)\n",
    "        \n",
    "        # Post-process and save predictions\n",
    "        for i, pred in enumerate(preds):\n",
    "            # Convert to binary mask\n",
    "            pred_binary = torch.where(pred > 0, 1, 0).float()\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            pred_np = DT.get_reverse_transform_to_numpy()(pred_binary)[:, :, 0]\n",
    "            pred_img = Image.fromarray((pred_np * 255).astype(np.uint8))\n",
    "            \n",
    "            # Save prediction\n",
    "            output_path = os.path.join(output_dir, f\"{batch_ids[i]}.png\")\n",
    "            pred_img.save(output_path)\n",
    "            \n",
    "        if (step + 1) % 10 == 0:\n",
    "            print(f\"Processed {step + 1}/{len(te_dataloader)} batches\")\n",
    "\n",
    "print(f\"\\nPrediction completed! Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac4fea",
   "metadata": {},
   "source": [
    "## Visualization of Results\n",
    "\n",
    "Display some prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3bd172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some results\n",
    "test_images = glob.glob(os.path.join(config[\"dataset\"][\"data_dir\"], \"test\", \"images\", \"*.jpg\"))\n",
    "predicted_masks = glob.glob(os.path.join(output_dir, \"*.png\"))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for i in range(min(5, len(test_images))):\n",
    "    # Load original image\n",
    "    img_name = os.path.basename(test_images[i]).replace('.jpg', '')\n",
    "    img = Image.open(test_images[i]).convert('RGB')\n",
    "    \n",
    "    # Load predicted mask\n",
    "    pred_path = os.path.join(output_dir, f\"{img_name}.png\")\n",
    "    if os.path.exists(pred_path):\n",
    "        pred_mask = Image.open(pred_path).convert('L')\n",
    "    else:\n",
    "        pred_mask = Image.new('L', img.size, 0)\n",
    "    \n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f\"Test Image {i+1}\")\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(pred_mask, cmap='gray')\n",
    "    axes[1, i].set_title(f\"Predicted Mask {i+1}\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc3d1da",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training and prediction completed successfully!\n",
    "\n",
    "### Files Created:\n",
    "- **Model weights**: Saved in `weights/` directory\n",
    "- **Predicted masks**: Saved in `predicted_masks/` directory\n",
    "- **Training logs**: Available in tensorboard logs\n",
    "\n",
    "### Next Steps:\n",
    "1. Review the predicted masks in the output folder\n",
    "2. Evaluate the model performance if you have ground truth for validation\n",
    "3. Fine-tune hyperparameters if needed\n",
    "4. Use the trained model for inference on new data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
